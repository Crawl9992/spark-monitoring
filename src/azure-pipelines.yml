# Build Spark Monitor with Maven
pool:
  # https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=vsts&tabs=yaml#use-a-microsoft-hosted-agent
  vmImage: 'ubuntu-16.04' # options: 'macOS-10.13', 'vs2017-win2016', 'ubuntu-16.04'

steps:
# Build with Apache Maven
- task: Maven@3
  inputs:
    mavenPomFile: '$(build.sourcesDirectory)/src/pom.xml' 
    jdkVersionOption: '1.8' # Optional. Options: default, 1.11, 1.10, 1.9, 1.8, 1.7, 1.6

- bash: |
    #!/bin/bash
    STAGE_DIR=/src
    echo "Copying listener jar"
    cp -f "$STAGE_DIR/spark-listeners/target/spark-listeners-1.0-SNAPSHOT.jar" "$STAGE_DIR/monitoring-staging" || { echo "Error copying file"; exit 1;}
    dir "$STAGE_DIR/monitoring-staging"
  workingDirectory: $(build.sourcesDirectory)
  displayName: Copy Files to Staging Directory
  failOnStderr: true
  #env:
  #  StagingDir: ./src
  
# Copy build .jar(s) to specific Azure Databricks DBFS
- powershell: |
    New-Item -ItemType Directory -Force -Path ./psmodules
    Save-Module -Name azure.databricks.cicd.tools -RequiredVersion 1.1.13 -Path ./psmodules
    Import-Module ./psmodules/azure.databricks.cicd.tools/1.1.13/azure.databricks.cicd.Tools.psm1
    $targetFolder = "/databricks/monitoring-staging"
    $parentFolder = "./src/monitoring-staging/"
    Write-Host "Source Folder Location - " $parentFolder
    Add-DatabricksDBFSFile -BearerToken $env:DatabricksToken -Region $env:DatabricksRegion -LocalRootFolder $parentFolder -FilePattern *.* -TargetLocation $targetFolder
    Write-Host "Target Folder - " $targetFolder
    Write-Host (Get-DatabricksDBFSFolder -BearerToken $env:DatabricksToken -Region $env:DatabricksRegion -Path $targetFolder)
  displayName: Copy Package to Databricks
  name: CopyDatabricksPackage
  workingDirectory: $(build.sourcesDirectory)
  failOnStderr: true
  env:
    DatabricksToken: $(DatabricksToken)
    DatabricksRegion: $(DatabricksRegion)